import os
os.environ["STREAMLIT_SERVER_FILEWATCHER_TYPE"] = "none"  # –æ—Ç–∫–ª—é—á–∞–µ–º file-watcher –Ω–∞ —Ö–æ—Å—Ç–∏–Ω–≥–∞—Ö

import streamlit as st
import pandas as pd

from starlinker.config import get_api_key
from starlinker.youtube_client import get_youtube_client
from starlinker.search import search_channels_by_keyword
from starlinker.channel_stats import fetch_channels_stats, get_avg_views_for_period
from starlinker.dedupe import build_title_blocklist

st.set_page_config(page_title="StarLinker", page_icon="üîé", layout="wide")
st.title("üîé StarLinker ‚Äî –ü–æ–∏—Å–∫ –±–ª–æ–≥–µ—Ä–æ–≤ –Ω–∞ YouTube")

API_KEY = get_api_key()
if not API_KEY:
    st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω YOUTUBE_API_KEY. –í Streamlit ‚Üí Settings ‚Üí Secrets –¥–æ–±–∞–≤—å –∫–ª—é—á.")
    st.stop()

with st.sidebar:
    st.subheader("üéõÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    intensity = st.selectbox(
        "–ò–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞",
        ["–ù–∏–∑–∫–∞—è (–¥—ë—à–µ–≤–æ)", "–°—Ä–µ–¥–Ω—è—è (—Å–±–∞–ª–∞–Ω—Å.)", "–í—ã—Å–æ–∫–∞—è (–≥–ª—É–±–æ–∫–æ)"],
        index=1
    )
    # –ø—Ä–µ—Å–µ—Ç—ã –≥–ª—É–±–∏–Ω—ã/—Å—Ç–æ–∏–º–æ—Å—Ç–∏
    PRESETS = {
        "–ù–∏–∑–∫–∞—è (–¥—ë—à–µ–≤–æ)":  {"pages": 1, "max_ch_per_kw": 80,  "videos_for_avg": 40,  "by_channel": True},
        "–°—Ä–µ–¥–Ω—è—è (—Å–±–∞–ª–∞–Ω—Å.)": {"pages": 2, "max_ch_per_kw": 200, "videos_for_avg": 80,  "by_channel": False},
        "–í—ã—Å–æ–∫–∞—è (–≥–ª—É–±–æ–∫–æ)": {"pages": 3, "max_ch_per_kw": 350, "videos_for_avg": 120, "by_channel": False},
    }
    P = PRESETS[intensity]

    st.markdown("---")
    st.subheader("üìä –§–∏–ª—å—Ç—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞")
    min_subs = st.number_input("–ú–∏–Ω. –ø–æ–¥–ø–∏—Å—á–∏–∫–æ–≤", value=1_000, step=500)
    min_avg_period = st.number_input("–ú–∏–Ω. —Å—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –∑–∞ –ø–µ—Ä–∏–æ–¥", value=2_000, step=100)
    period_days = st.number_input("–ü–µ—Ä–∏–æ–¥ (–¥–Ω–µ–π)", 1, 90, 30)

    st.markdown("---")
    st.subheader("üóÇÔ∏è –ë–∞–∑–∞ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è (–æ–¥–∏–Ω —Å—Ç–æ–ª–±–µ—Ü ‚Äî –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤)")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏ Excel/CSV", type=["xlsx", "csv"])

    st.caption("–ü–æ–¥ –∫–∞–ø–æ—Ç–æ–º –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à –∏ –±—ç—Ç—á–∏ API, —á—Ç–æ–±—ã —ç–∫–æ–Ω–æ–º–∏—Ç—å –∫–≤–æ—Ç—É.")

keywords_input = st.text_area("–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (–ø–æ –æ–¥–Ω–æ–º—É –≤ —Å—Ç—Ä–æ–∫–µ)")
keywords = [k.strip() for k in keywords_input.splitlines() if k.strip()]

if st.button("üîç –ù–∞–π—Ç–∏ –±–ª–æ–≥–µ—Ä–æ–≤"):
    if not keywords:
        st.error("‚ùå –í–≤–µ–¥–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ!")
        st.stop()

    yt = get_youtube_client(API_KEY)

    # 0) –ß–∏—Ç–∞–µ–º –±–∞–∑—É ‚Äî —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏—è (lower/trim/—Å—Ö–ª–æ–ø–Ω—É—Ç—ã–µ –ø—Ä–æ–±–µ–ª—ã)
    title_blocklist = set()
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith(".csv"):
                df_in = pd.read_csv(uploaded_file)
            else:
                # –µ—Å–ª–∏ –≤ –∫–Ω–∏–≥–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Å—Ç–æ–≤ ‚Äî –æ–±—ä–µ–¥–∏–Ω–∏–º
                raw = pd.read_excel(uploaded_file, sheet_name=None)
                if isinstance(raw, dict):
                    df_in = pd.concat(raw.values(), ignore_index=True, sort=False)
                else:
                    df_in = raw
            title_blocklist = build_title_blocklist(df_in)
            st.info(f"üìÇ –î–µ–¥—É–ø –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—è–º: –∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(title_blocklist)} –∫–∞–Ω–∞–ª–æ–≤ –∏–∑ –±–∞–∑—ã")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª: {e}")

    # 1) –ü–æ–∏—Å–∫ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ –∫–ª—é—á–∞–º (–≤ –æ–¥–∏–Ω —Å–ª–æ–≤–∞—Ä—å)
    all_channels: dict[str, str] = {}
    prog = st.progress(0)
    note = st.empty()
    for i, kw in enumerate(keywords, start=1):
        note.write(f"üîé –ü–æ–∏—Å–∫ ¬´{kw}¬ª ({i}/{len(keywords)}) ‚Ä¶")
        found = search_channels_by_keyword(
            yt, kw,
            max_pages=P["pages"],
            max_channels=P["max_ch_per_kw"],
            by_channel=P["by_channel"]
        )
        for cid, title in found.items():
            all_channels.setdefault(cid, title)
        prog.progress(int(i / max(1, len(keywords)) * 25))

    if not all_channels:
        st.warning("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ —ç—Ç–∞–ø–µ –ø–æ–∏—Å–∫–∞ (–ø–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞).")
        st.stop()

    # 2) –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–∞–Ω–∞–ª–æ–≤ (–±–∞—Ç—á)
    note.write(f"üì¶ –ü–æ–ª—É—á–∞—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ {len(all_channels)} –∫–∞–Ω–∞–ª–∞–º‚Ä¶")
    stats = fetch_channels_stats(yt, list(all_channels.keys()))
    prog.progress(60)

    # 3) –î–µ–¥—É–ø –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –±–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞)
    def norm_title(x: str | None) -> str:
        return " ".join((x or "").strip().lower().split())

    if title_blocklist:
        before = len(stats)
        drop_ids = [cid for cid, s in stats.items() if norm_title(s.get("title") or all_channels.get(cid)) in title_blocklist]
        for cid in drop_ids:
            stats.pop(cid, None); all_channels.pop(cid, None)
        st.caption(f"üßπ –ò—Å–∫–ª—é—á–µ–Ω–æ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –∏–∑ –±–∞–∑—ã: {before - len(stats)}")
    prog.progress(65)

    # 4) –§–∏–ª—å—Ç—Ä –ø–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º (total views —É–±—Ä–∞–ª–∏ –∏–∑ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ä–µ–∂–∏–º–∞)
    base_pass = [cid for cid, s in stats.items() if s.get("uploads_playlist_id") and s.get("subs", 0) >= min_subs]
    if not base_pass:
        st.warning("–ù–∏–∫—Ç–æ –Ω–µ –ø—Ä–æ—à—ë–ª —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–æ–¥–ø–∏—Å—á–∏–∫–∞–º.")
        st.stop()

    # 5) –°—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã –∑–∞ –ø–µ—Ä–∏–æ–¥
    rows = []
    for i, cid in enumerate(base_pass, start=1):
        t = stats[cid].get("title") or all_channels.get(cid, cid)
        note.write(f"‚è±Ô∏è {i}/{len(base_pass)} ‚Ä¢ –°—Ä–µ–¥–Ω–∏–µ –∑–∞ {period_days} –¥–Ω.: {t}")
        avg, count = get_avg_views_for_period(yt, stats[cid]["uploads_playlist_id"], period_days, P["videos_for_avg"])
        if avg is None or avg < min_avg_period:
            prog.progress(65 + int(35 * i / len(base_pass)))
            continue
        rows.append({
            "–ö–∞–Ω–∞–ª": t,
            "–ü–æ–¥–ø–∏—Å—á–∏–∫–∏": stats[cid]["subs"],
            "–°—Ä–µ–¥–Ω–∏–µ_–∑–∞_–¥–Ω–∏": avg,
            "–í–∏–¥–µ–æ_–∑–∞_–¥–Ω–∏": count,
            "–°—Ç—Ä–∞–Ω–∞": stats[cid]["country"],
            "–°—Å—ã–ª–∫–∞": f"https://www.youtube.com/channel/{cid}",
            "channel_id": cid
        })
        prog.progress(65 + int(35 * i / len(base_pass)))

    note.empty(); prog.empty()

    if rows:
        df = pd.DataFrame(rows).drop_duplicates(subset=["channel_id"])
        df = df.sort_values(by=["–°—Ä–µ–¥–Ω–∏–µ_–∑–∞_–¥–Ω–∏", "–ü–æ–¥–ø–∏—Å—á–∏–∫–∏"], ascending=[False, False])
        st.success(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(df)} –∫–∞–Ω–∞–ª–æ–≤")
        st.dataframe(df.drop(columns=["channel_id"]), use_container_width=True)
        xlsx = "bloggers.xlsx"
        df.to_excel(xlsx, index=False)
        with open(xlsx, "rb") as f:
            st.download_button("üì• –°–∫–∞—á–∞—Ç—å Excel", f, file_name="bloggers.xlsx")
    else:
        st.warning("–ü–æ –∑–∞–¥–∞–Ω–Ω—ã–º —É—Å–ª–æ–≤–∏—è–º –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –û—Å–ª–∞–±—å —Ñ–∏–ª—å—Ç—Ä ¬´–ú–∏–Ω. —Å—Ä–µ–¥–Ω–∏–µ –ø—Ä–æ—Å–º–æ—Ç—Ä—ã¬ª –∏–ª–∏ —É–≤–µ–ª–∏—á—å –ø–µ—Ä–∏–æ–¥.")
