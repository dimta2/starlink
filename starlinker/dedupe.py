from typing import Tuple, Set, Dict, List
import pandas as pd
import streamlit as st
from .normalize import extract_uc_id, extract_handle, resolve_handle_to_channel_id

# –∫–æ–ª–æ–Ω–∫–∏, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –∏–∑–≤–ª–µ–∫–∞–µ–º handle/—Å—Å—ã–ª–∫–∏/–Ω–∞–∑–≤–∞–Ω–∏—è
_HANDLE_LIKE_COLS = {"handle", "username", "user", "–Ω–∏–∫", "–Ω–∏–∫–Ω–µ–π–º", "–∞–∫–∫–∞—É–Ω—Ç", "account"}
_URL_LIKE_COLS = {"link", "url", "—Å—Å—ã–ª–∫–∞"}
_TITLE_LIKE_COLS = {"name", "title", "channel", "–∫–∞–Ω–∞–ª", "–Ω–∞–∑–≤–∞–Ω–∏–µ", "–∏–º—è", "channel_name", "channel title"}

def _norm_title(x: str | None) -> str:
    return " ".join((x or "").strip().lower().split())

def load_existing_ids(
    youtube,
    df: pd.DataFrame,
    treat_bare_names: bool,
    do_normalize: bool,
    max_to_normalize: int
) -> Tuple[Set[str], Set[str], Set[str], Dict[str, int]]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (existing_ids, existing_handles, existing_titles, stats)
    """
    stats = {"taken_channel_id": 0, "extracted_from_url": 0, "normalized": 0, "unresolved": 0, "handles": 0, "titles": 0}
    existing_ids: Set[str] = set()
    existing_handles: Set[str] = set()
    existing_titles: Set[str] = set()

    # 1) channel_id –∏–∑ —è–≤–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∏ –∏–∑ –ª—é–±—ã—Ö —Å—Å—ã–ª–æ–∫ (–∏—â–µ–º UC‚Ä¶ –≤ —Ç–µ–∫—Å—Ç–µ)
    cols_lower = {c.lower(): c for c in df.columns}
    cid_col = next((orig for k, orig in cols_lower.items() if k in {"channel_id", "id"} or k.endswith("channel_id")), None)

    if cid_col:
        for v in df[cid_col].dropna():
            uc = extract_uc_id(str(v))
            if uc:
                existing_ids.add(uc); stats["taken_channel_id"] += 1

    for c in df.columns:
        for v in df[c].dropna():
            uc = extract_uc_id(str(v))
            if uc:
                existing_ids.add(uc); stats["extracted_from_url"] += 1

    # 2) handles ‚Äî —Ç–æ–ª—å–∫–æ –∏–∑ ¬´–ø–æ—Ö–æ–∂–∏—Ö¬ª –∫–æ–ª–æ–Ω–æ–∫ (–∏/–∏–ª–∏ treat_bare_names)
    for c in df.columns:
        cl = c.lower()
        consider_bare = treat_bare_names or (cl in _HANDLE_LIKE_COLS)
        for v in df[c].dropna():
            h = extract_handle(str(v), treat_bare_names=consider_bare)
            if h:
                existing_handles.add(h)
    stats["handles"] = len(existing_handles)

    # 3) titles ‚Äî –∏–∑ ¬´–ø–æ—Ö–æ–∂–∏—Ö¬ª –∫–æ–ª–æ–Ω–æ–∫, –≤–∫–ª—é—á–∞—è –ª–∏—Å—Ç raw_input
    for c in df.columns:
        cl = c.lower()
        if (cl in _TITLE_LIKE_COLS) or any(tok in cl for tok in ["title", "channel", "–∫–∞–Ω–∞–ª", "–Ω–∞–∑–≤"]):
            for v in df[c].dropna():
                nt = _norm_title(str(v))
                if nt:  
                    existing_titles.add(nt)
    stats["titles"] = len(existing_titles)

    # 4) (–æ–ø—Ü.) –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —á–∞—Å—Ç–∏ handle ‚Üí channel_id (–¥–æ—Ä–æ–≥–æ)
    if do_normalize and existing_handles:
        uniq = list(dict.fromkeys(existing_handles))[: max_to_normalize]
        resolved = 0
        prog = st.progress(0); status = st.empty()
        for i, h in enumerate(uniq, start=1):
            status.write(f"üîÅ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è @{h} ({i}/{len(uniq)})")
            uc = resolve_handle_to_channel_id(youtube, h)
            if uc:
                existing_ids.add(uc); resolved += 1
            prog.progress(int(i / max(1, len(uniq)) * 100))
        prog.empty(); status.empty()
        stats["normalized"] = resolved
        stats["unresolved"] = max(0, len(uniq) - resolved)

    return existing_ids, existing_handles, existing_titles, stats
